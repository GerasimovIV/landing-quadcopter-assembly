{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тут описан основной алгоритм получения 3d карты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Подключаем все необходимые библиотеки и загружаем данные с калиброки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import PIL.ExifTags\n",
    "import PIL.Image\n",
    "from matplotlib import pyplot as plt \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# and projection matrix in the new (rectified) coordinate systems for the second camera.\n",
    "line = './calibration/camera_params/stereo_params/'\n",
    "ret = np.load(line + 'ret.npy')\n",
    "K_left = np.load(line + 'K_left.npy')\n",
    "K_right = np.load(line + 'K_right.npy')\n",
    "dist_left = np.load(line + 'dist_left.npy')\n",
    "dist_right = np.load(line + 'dist_right.npy')\n",
    "R = np.load(line + 'R.npy')\n",
    "T = np.load(line + 'T.npy')\n",
    "image_size = np.load(line + 'image_size.npy')\n",
    "image_size = (image_size[1], image_size[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Учитывая внутренние коэффициенты и коэффициенты искажения для обеих камер, а также перемещение и вращение, которые связаны с расположением одной камеры относительно другой, stereoRectify () рассчитывает для нас выпрямление, проекцию, и матрицу диспаратности, которые нам нужны для извлечения информации о глубине из стереоизображений с этой пары камер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_left, R_right, P_left, P_right, Q, roi_left, roi_right = cv2.stereoRectify(cameraMatrix1 = K_left, \n",
    "                                                  cameraMatrix2 = K_right, \n",
    "                                                  distCoeffs1 = dist_left, \n",
    "                                                  distCoeffs2 = dist_right, \n",
    "                                                  imageSize = image_size, \n",
    "                                                  R = R, \n",
    "                                                  T = T,\n",
    "                                                  alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204, 167, 2264, 1604)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 169, 2238, 1590)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = (204, 169, 2238, 1590)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Функция, которая реализует математику, изображенную на рисунке ниже, называется initUndistortRectifyMap(). Мы вызываем эту функцию дважды, один раз для левой и один раз дляправильное изображение стереопары:\n",
    "<img src=\"1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1_left, map2_left = cv2.initUndistortRectifyMap( cameraMatrix = K_left,\n",
    "                                         distCoeffs = dist_left, \n",
    "                                         R = R_left,\n",
    "                                         newCameraMatrix = P_left, \n",
    "                                         size = image_size,\n",
    "                                         m1type = cv2.CV_32FC2)\n",
    "map1_right, map2_right = cv2.initUndistortRectifyMap( cameraMatrix = K_right,\n",
    "                                         distCoeffs = dist_right, \n",
    "                                         R = R_right,\n",
    "                                         newCameraMatrix = P_right, \n",
    "                                         size = image_size,\n",
    "                                         m1type = cv2.CV_32FC2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Подготовительные работы выполнены, сейчас можно брать два изображения и обрабатывать их. На данном шаге загружаем изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify image paths\n",
    "img_path1 = './calibration/calibration_images/new/25791059/87.png'\n",
    "img_path2 = './calibration/calibration_images/new/25797059/87.png'\n",
    "\n",
    "\n",
    "\n",
    "#Load pictures\n",
    "img_1 = cv2.imread(img_path1)\n",
    "img_2 = cv2.imread(img_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Применяем к ним всё, что было на рисунке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_left = cv2.remap(src = img_1,\n",
    "                     map1 = map1_left,\n",
    "                     map2 = map2_left,\n",
    "                     interpolation = cv2.INTER_NEAREST)\n",
    "dst_right = cv2.remap(src = img_2,\n",
    "                     map1 = map1_right,\n",
    "                     map2 = map2_right,\n",
    "                     interpolation = cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#plt.imshow(dst_left)\n",
    "cv2.imwrite('dst_left.png', dst_left)\n",
    "#plt.imshow(dst_right)\n",
    "cv2.imwrite('dst_right.png', dst_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, border):\n",
    "    return image[border[1]:border[3], border[0]:border[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_left_crop = crop_image(dst_left, roi_left)\n",
    "dst_right_crop = crop_image(dst_right, roi_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dst_left_crop) == np.shape(dst_right_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('dst_left_crop.png', dst_left_crop)\n",
    "cv2.imwrite('dst_right_crop.png', dst_right_crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Для карты диспартности нам понадобятся некоторые вспомогательные функции. Одна из них просто сохраняет файл ply в удобном виде, а другая - понижает качество изображения для ускрения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output(vertices, colors, filename):\n",
    "    colors = colors.reshape(-1,3)\n",
    "    vertices = np.hstack([vertices.reshape(-1,3),colors])\n",
    "\n",
    "    ply_header = '''ply\n",
    "        format ascii 1.0\n",
    "        element vertex %(vert_num)d\n",
    "        property float x\n",
    "        property float y\n",
    "        property float z\n",
    "        property uchar red\n",
    "        property uchar green\n",
    "        property uchar blue\n",
    "        end_header\n",
    "        '''\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(ply_header %dict(vert_num=len(vertices)))\n",
    "        np.savetxt(f,vertices,'%f %f %f %d %d %d')\n",
    "def downsample_image(image, reduce_factor):\n",
    "    for i in range(0,reduce_factor):\n",
    "        #Check if image is color or grayscale\n",
    "        if len(image.shape) > 2:\n",
    "            row,col = image.shape[:2]\n",
    "        else:\n",
    "            row,col = image.shape\n",
    "\n",
    "        image = cv2.pyrDown(image, dstsize= (col//2, row // 2))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Теперь используя алгоритм SGBM мы находим карту диспартности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "win_size = 5\n",
    "min_disp = -1\n",
    "max_disp = 63 #min_disp * 9\n",
    "num_disp = max_disp - min_disp # Needs to be divisible by 16\n",
    "stereo = cv2.StereoSGBM_create(minDisparity= 0,\n",
    "    numDisparities = 16,\n",
    "    blockSize = 3,\n",
    "    uniquenessRatio = 0,\n",
    "    speckleWindowSize = 0,\n",
    "    speckleRange = 0,\n",
    "    disp12MaxDiff = 0,\n",
    "    P1 = 0,#8*3*win_size**2,\n",
    "    P2 = 0) #32*3*win_size**2)\n",
    "\n",
    "#Compute disparity map\n",
    "#print (\"\\nComputing the disparity  map...\")\n",
    "dst_left_crop_d = downsample_image(dst_left_crop, 3)\n",
    "dst_right_crop_d = downsample_image(dst_right_crop, 3)\n",
    "#plt.imshow(dst_left)\n",
    "cv2.imwrite('dst_left_crop_d.png', dst_left_crop_d)\n",
    "#plt.imshow(dst_right)\n",
    "cv2.imwrite('dst_right_crop_d.png', dst_right_crop_d)\n",
    "\n",
    "disparity_map = stereo.compute(dst_left_crop_d, dst_right_crop_d)\n",
    "cv2.imwrite('disparity_map.png', disparity_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Восстанавливаем 3D карту при помощи reprojectImageTo3D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Creating the output file... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "focal_length = 8\n",
    "Q2 = np.float32([[1,0,0,0],\n",
    "                [0,-1,0,0],\n",
    "                [0,0,focal_length*0.05,0], #Focal length multiplication obtained experimentally. \n",
    "                [0,0,0,1]])\n",
    "\n",
    "points_3D = cv2.reprojectImageTo3D(disparity_map, Q2)\n",
    "#Get color points\n",
    "colors = cv2.cvtColor(dst_left_crop_d, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Get rid of points with value 0 (i.e no depth)\n",
    "mask_map = disparity_map > disparity_map.min() #and disparity_map < disparity_map.max()\n",
    "\n",
    "#Mask colors and points. \n",
    "output_points = points_3D[mask_map]\n",
    "output_colors = colors[mask_map]\n",
    "\n",
    "#Define name for output file\n",
    "output_file = 'cotik.ply'\n",
    "\n",
    "\n",
    "ox_p = np.array([[i, 0, 0] for i in range(50)])\n",
    "oy_p = np.array([[0, i, 0] for i in range(50)])\n",
    "oz_p = np.array([[0, 0, i] for i in range(50)])\n",
    "ox_c = np.array([[255, 0, 0] for i in range(50)])\n",
    "oy_c = np.array([[0, 255, 0] for i in range(50)])\n",
    "oz_c = np.array([[0, 0, 255] for i in range(50)])\n",
    "axis_p = np.concatenate((ox_p, oy_p, oz_p))\n",
    "axis_c = np.concatenate((ox_c, oy_c, oz_c))\n",
    "output_points = np.concatenate((output_points, axis_p))\n",
    "output_colors = np.concatenate((output_colors, axis_c))\n",
    "\n",
    "\n",
    "\n",
    "#Generate point cloud \n",
    "print (\"\\n Creating the output file... \\n\")\n",
    "create_output(output_points, output_colors, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
